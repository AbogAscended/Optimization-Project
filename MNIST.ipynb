{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T23:59:08.025255Z",
     "start_time": "2025-04-15T23:59:02.033175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from NeuralNet import NeuralNetwork\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .1\n",
    "batch_size = 32\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MNIST('data',train=True,download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_data = MNIST('data',train=False,download=True, transform=torchvision.transforms.ToTensor())\n",
    "mnist_train = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "mnist_test = DataLoader(test_data, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    avg_loss = np.empty(0)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        avg_loss = np.append(avg_loss, loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    scheduler.step(torch.mean(torch.tensor(avg_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305026  [   32/60000]\n",
      "loss: 2.277832  [ 3232/60000]\n",
      "loss: 2.053226  [ 6432/60000]\n",
      "loss: 1.121153  [ 9632/60000]\n",
      "loss: 0.727683  [12832/60000]\n",
      "loss: 0.637947  [16032/60000]\n",
      "loss: 0.474825  [19232/60000]\n",
      "loss: 0.531527  [22432/60000]\n",
      "loss: 0.878165  [25632/60000]\n",
      "loss: 0.244950  [28832/60000]\n",
      "loss: 0.314103  [32032/60000]\n",
      "loss: 0.214694  [35232/60000]\n",
      "loss: 0.236980  [38432/60000]\n",
      "loss: 0.367572  [41632/60000]\n",
      "loss: 0.359523  [44832/60000]\n",
      "loss: 0.352870  [48032/60000]\n",
      "loss: 0.835158  [51232/60000]\n",
      "loss: 0.296905  [54432/60000]\n",
      "loss: 0.379312  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.344620 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.134580  [   32/60000]\n",
      "loss: 0.241414  [ 3232/60000]\n",
      "loss: 0.210539  [ 6432/60000]\n",
      "loss: 0.299511  [ 9632/60000]\n",
      "loss: 0.122107  [12832/60000]\n",
      "loss: 0.225581  [16032/60000]\n",
      "loss: 0.237514  [19232/60000]\n",
      "loss: 0.257810  [22432/60000]\n",
      "loss: 0.175582  [25632/60000]\n",
      "loss: 0.097909  [28832/60000]\n",
      "loss: 0.068802  [32032/60000]\n",
      "loss: 0.072457  [35232/60000]\n",
      "loss: 0.600858  [38432/60000]\n",
      "loss: 0.114642  [41632/60000]\n",
      "loss: 0.188868  [44832/60000]\n",
      "loss: 0.175988  [48032/60000]\n",
      "loss: 0.417106  [51232/60000]\n",
      "loss: 0.298833  [54432/60000]\n",
      "loss: 0.264210  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.247410 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.554580  [   32/60000]\n",
      "loss: 0.329992  [ 3232/60000]\n",
      "loss: 0.153493  [ 6432/60000]\n",
      "loss: 0.275186  [ 9632/60000]\n",
      "loss: 0.041706  [12832/60000]\n",
      "loss: 0.487962  [16032/60000]\n",
      "loss: 0.307927  [19232/60000]\n",
      "loss: 0.059906  [22432/60000]\n",
      "loss: 0.182588  [25632/60000]\n",
      "loss: 0.283884  [28832/60000]\n",
      "loss: 0.260346  [32032/60000]\n",
      "loss: 0.294097  [35232/60000]\n",
      "loss: 0.185300  [38432/60000]\n",
      "loss: 0.238463  [41632/60000]\n",
      "loss: 0.173983  [44832/60000]\n",
      "loss: 0.294132  [48032/60000]\n",
      "loss: 0.136884  [51232/60000]\n",
      "loss: 0.211586  [54432/60000]\n",
      "loss: 0.200055  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.228728 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.123296  [   32/60000]\n",
      "loss: 0.340436  [ 3232/60000]\n",
      "loss: 0.246448  [ 6432/60000]\n",
      "loss: 0.625633  [ 9632/60000]\n",
      "loss: 0.242903  [12832/60000]\n",
      "loss: 0.180824  [16032/60000]\n",
      "loss: 0.135877  [19232/60000]\n",
      "loss: 0.069368  [22432/60000]\n",
      "loss: 0.425114  [25632/60000]\n",
      "loss: 0.211660  [28832/60000]\n",
      "loss: 0.104192  [32032/60000]\n",
      "loss: 0.046869  [35232/60000]\n",
      "loss: 0.101267  [38432/60000]\n",
      "loss: 0.088546  [41632/60000]\n",
      "loss: 0.378633  [44832/60000]\n",
      "loss: 0.124659  [48032/60000]\n",
      "loss: 0.131652  [51232/60000]\n",
      "loss: 0.089558  [54432/60000]\n",
      "loss: 0.302009  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.221812 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.075313  [   32/60000]\n",
      "loss: 0.230135  [ 3232/60000]\n",
      "loss: 0.516327  [ 6432/60000]\n",
      "loss: 0.050041  [ 9632/60000]\n",
      "loss: 0.199140  [12832/60000]\n",
      "loss: 0.160952  [16032/60000]\n",
      "loss: 0.075655  [19232/60000]\n",
      "loss: 0.096793  [22432/60000]\n",
      "loss: 0.198358  [25632/60000]\n",
      "loss: 0.218420  [28832/60000]\n",
      "loss: 0.140723  [32032/60000]\n",
      "loss: 0.017847  [35232/60000]\n",
      "loss: 0.189350  [38432/60000]\n",
      "loss: 0.129328  [41632/60000]\n",
      "loss: 0.151860  [44832/60000]\n",
      "loss: 0.293005  [48032/60000]\n",
      "loss: 0.266253  [51232/60000]\n",
      "loss: 0.268113  [54432/60000]\n",
      "loss: 0.121578  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.226526 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.072529  [   32/60000]\n",
      "loss: 0.108487  [ 3232/60000]\n",
      "loss: 0.449258  [ 6432/60000]\n",
      "loss: 0.062525  [ 9632/60000]\n",
      "loss: 0.173125  [12832/60000]\n",
      "loss: 0.101214  [16032/60000]\n",
      "loss: 0.288820  [19232/60000]\n",
      "loss: 0.099518  [22432/60000]\n",
      "loss: 0.462332  [25632/60000]\n",
      "loss: 0.114473  [28832/60000]\n",
      "loss: 0.303613  [32032/60000]\n",
      "loss: 0.068025  [35232/60000]\n",
      "loss: 0.374273  [38432/60000]\n",
      "loss: 0.186952  [41632/60000]\n",
      "loss: 0.536059  [44832/60000]\n",
      "loss: 0.246264  [48032/60000]\n",
      "loss: 0.151727  [51232/60000]\n",
      "loss: 0.221385  [54432/60000]\n",
      "loss: 0.335299  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.208639 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.239561  [   32/60000]\n",
      "loss: 0.057112  [ 3232/60000]\n",
      "loss: 0.024716  [ 6432/60000]\n",
      "loss: 0.256131  [ 9632/60000]\n",
      "loss: 0.620170  [12832/60000]\n",
      "loss: 0.085537  [16032/60000]\n",
      "loss: 0.119606  [19232/60000]\n",
      "loss: 0.231536  [22432/60000]\n",
      "loss: 0.092397  [25632/60000]\n",
      "loss: 0.382342  [28832/60000]\n",
      "loss: 0.100489  [32032/60000]\n",
      "loss: 0.310735  [35232/60000]\n",
      "loss: 0.426496  [38432/60000]\n",
      "loss: 0.043554  [41632/60000]\n",
      "loss: 0.366755  [44832/60000]\n",
      "loss: 0.042718  [48032/60000]\n",
      "loss: 0.067558  [51232/60000]\n",
      "loss: 0.146020  [54432/60000]\n",
      "loss: 0.137486  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.235439 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.179967  [   32/60000]\n",
      "loss: 0.180934  [ 3232/60000]\n",
      "loss: 0.115724  [ 6432/60000]\n",
      "loss: 0.421334  [ 9632/60000]\n",
      "loss: 0.230097  [12832/60000]\n",
      "loss: 0.108597  [16032/60000]\n",
      "loss: 0.132355  [19232/60000]\n",
      "loss: 0.105887  [22432/60000]\n",
      "loss: 0.053259  [25632/60000]\n",
      "loss: 0.060502  [28832/60000]\n",
      "loss: 0.040401  [32032/60000]\n",
      "loss: 0.205033  [35232/60000]\n",
      "loss: 0.148240  [38432/60000]\n",
      "loss: 0.265071  [41632/60000]\n",
      "loss: 0.487190  [44832/60000]\n",
      "loss: 0.323482  [48032/60000]\n",
      "loss: 0.098390  [51232/60000]\n",
      "loss: 0.157062  [54432/60000]\n",
      "loss: 0.259359  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.214165 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.223457  [   32/60000]\n",
      "loss: 0.193830  [ 3232/60000]\n",
      "loss: 0.147724  [ 6432/60000]\n",
      "loss: 0.164793  [ 9632/60000]\n",
      "loss: 0.050694  [12832/60000]\n",
      "loss: 0.218522  [16032/60000]\n",
      "loss: 0.104763  [19232/60000]\n",
      "loss: 0.343772  [22432/60000]\n",
      "loss: 0.360751  [25632/60000]\n",
      "loss: 0.079149  [28832/60000]\n",
      "loss: 0.071342  [32032/60000]\n",
      "loss: 0.212320  [35232/60000]\n",
      "loss: 0.086133  [38432/60000]\n",
      "loss: 0.514976  [41632/60000]\n",
      "loss: 0.104566  [44832/60000]\n",
      "loss: 0.076892  [48032/60000]\n",
      "loss: 0.272765  [51232/60000]\n",
      "loss: 0.430421  [54432/60000]\n",
      "loss: 0.485965  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.207663 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.160350  [   32/60000]\n",
      "loss: 0.147552  [ 3232/60000]\n",
      "loss: 0.074720  [ 6432/60000]\n",
      "loss: 0.060759  [ 9632/60000]\n",
      "loss: 0.521981  [12832/60000]\n",
      "loss: 0.318014  [16032/60000]\n",
      "loss: 0.253073  [19232/60000]\n",
      "loss: 0.449271  [22432/60000]\n",
      "loss: 0.095680  [25632/60000]\n",
      "loss: 0.252553  [28832/60000]\n",
      "loss: 0.166531  [32032/60000]\n",
      "loss: 0.228179  [35232/60000]\n",
      "loss: 0.271393  [38432/60000]\n",
      "loss: 0.265538  [41632/60000]\n",
      "loss: 0.378427  [44832/60000]\n",
      "loss: 0.220417  [48032/60000]\n",
      "loss: 0.062269  [51232/60000]\n",
      "loss: 0.242990  [54432/60000]\n",
      "loss: 0.568858  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.212517 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.104941  [   32/60000]\n",
      "loss: 0.309279  [ 3232/60000]\n",
      "loss: 0.145492  [ 6432/60000]\n",
      "loss: 0.149926  [ 9632/60000]\n",
      "loss: 0.198491  [12832/60000]\n",
      "loss: 0.091501  [16032/60000]\n",
      "loss: 0.313596  [19232/60000]\n",
      "loss: 0.149781  [22432/60000]\n",
      "loss: 0.134441  [25632/60000]\n",
      "loss: 0.119138  [28832/60000]\n",
      "loss: 0.257216  [32032/60000]\n",
      "loss: 0.134936  [35232/60000]\n",
      "loss: 0.105531  [38432/60000]\n",
      "loss: 0.376409  [41632/60000]\n",
      "loss: 0.119810  [44832/60000]\n",
      "loss: 0.257877  [48032/60000]\n",
      "loss: 0.157503  [51232/60000]\n",
      "loss: 0.279048  [54432/60000]\n",
      "loss: 0.084038  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.218475 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.134708  [   32/60000]\n",
      "loss: 0.161327  [ 3232/60000]\n",
      "loss: 0.033977  [ 6432/60000]\n",
      "loss: 0.063744  [ 9632/60000]\n",
      "loss: 0.136947  [12832/60000]\n",
      "loss: 0.096719  [16032/60000]\n",
      "loss: 0.126059  [19232/60000]\n",
      "loss: 0.113918  [22432/60000]\n",
      "loss: 0.020470  [25632/60000]\n",
      "loss: 0.316920  [28832/60000]\n",
      "loss: 0.029177  [32032/60000]\n",
      "loss: 0.528291  [35232/60000]\n",
      "loss: 0.099533  [38432/60000]\n",
      "loss: 0.226448  [41632/60000]\n",
      "loss: 0.057833  [44832/60000]\n",
      "loss: 0.124709  [48032/60000]\n",
      "loss: 0.262461  [51232/60000]\n",
      "loss: 0.111992  [54432/60000]\n",
      "loss: 0.412042  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.198571 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.138982  [   32/60000]\n",
      "loss: 0.328523  [ 3232/60000]\n",
      "loss: 0.116218  [ 6432/60000]\n",
      "loss: 0.067340  [ 9632/60000]\n",
      "loss: 0.266576  [12832/60000]\n",
      "loss: 0.072797  [16032/60000]\n",
      "loss: 0.071138  [19232/60000]\n",
      "loss: 0.426059  [22432/60000]\n",
      "loss: 0.190867  [25632/60000]\n",
      "loss: 0.204140  [28832/60000]\n",
      "loss: 0.050506  [32032/60000]\n",
      "loss: 0.009779  [35232/60000]\n",
      "loss: 0.393363  [38432/60000]\n",
      "loss: 0.400448  [41632/60000]\n",
      "loss: 0.434446  [44832/60000]\n",
      "loss: 0.335856  [48032/60000]\n",
      "loss: 0.095019  [51232/60000]\n",
      "loss: 0.083221  [54432/60000]\n",
      "loss: 0.370191  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.191104 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.079634  [   32/60000]\n",
      "loss: 0.224820  [ 3232/60000]\n",
      "loss: 0.326625  [ 6432/60000]\n",
      "loss: 0.027772  [ 9632/60000]\n",
      "loss: 0.206214  [12832/60000]\n",
      "loss: 0.173627  [16032/60000]\n",
      "loss: 0.304837  [19232/60000]\n",
      "loss: 0.451597  [22432/60000]\n",
      "loss: 0.064215  [25632/60000]\n",
      "loss: 0.349766  [28832/60000]\n",
      "loss: 0.028521  [32032/60000]\n",
      "loss: 0.026329  [35232/60000]\n",
      "loss: 0.137727  [38432/60000]\n",
      "loss: 0.068671  [41632/60000]\n",
      "loss: 0.085266  [44832/60000]\n",
      "loss: 0.372433  [48032/60000]\n",
      "loss: 0.047760  [51232/60000]\n",
      "loss: 0.208785  [54432/60000]\n",
      "loss: 0.134000  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.194299 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.150393  [   32/60000]\n",
      "loss: 0.311562  [ 3232/60000]\n",
      "loss: 0.136733  [ 6432/60000]\n",
      "loss: 0.044240  [ 9632/60000]\n",
      "loss: 0.237953  [12832/60000]\n",
      "loss: 0.094185  [16032/60000]\n",
      "loss: 0.180293  [19232/60000]\n",
      "loss: 0.222278  [22432/60000]\n",
      "loss: 0.245191  [25632/60000]\n",
      "loss: 0.063435  [28832/60000]\n",
      "loss: 0.036221  [32032/60000]\n",
      "loss: 0.070078  [35232/60000]\n",
      "loss: 0.440841  [38432/60000]\n",
      "loss: 0.155139  [41632/60000]\n",
      "loss: 0.231333  [44832/60000]\n",
      "loss: 0.011283  [48032/60000]\n",
      "loss: 0.117965  [51232/60000]\n",
      "loss: 0.168482  [54432/60000]\n",
      "loss: 0.058735  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.196612 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.130008  [   32/60000]\n",
      "loss: 0.248314  [ 3232/60000]\n",
      "loss: 0.274231  [ 6432/60000]\n",
      "loss: 0.074448  [ 9632/60000]\n",
      "loss: 0.161642  [12832/60000]\n",
      "loss: 0.202161  [16032/60000]\n",
      "loss: 0.080221  [19232/60000]\n",
      "loss: 0.121510  [22432/60000]\n",
      "loss: 0.041397  [25632/60000]\n",
      "loss: 0.045904  [28832/60000]\n",
      "loss: 0.075473  [32032/60000]\n",
      "loss: 0.176190  [35232/60000]\n",
      "loss: 0.124167  [38432/60000]\n",
      "loss: 0.166096  [41632/60000]\n",
      "loss: 0.030869  [44832/60000]\n",
      "loss: 0.137704  [48032/60000]\n",
      "loss: 0.350291  [51232/60000]\n",
      "loss: 0.075895  [54432/60000]\n",
      "loss: 0.380031  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.198845 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.606042  [   32/60000]\n",
      "loss: 0.034231  [ 3232/60000]\n",
      "loss: 0.146562  [ 6432/60000]\n",
      "loss: 0.129889  [ 9632/60000]\n",
      "loss: 0.129992  [12832/60000]\n",
      "loss: 0.307982  [16032/60000]\n",
      "loss: 0.115330  [19232/60000]\n",
      "loss: 0.931957  [22432/60000]\n",
      "loss: 0.028931  [25632/60000]\n",
      "loss: 0.259781  [28832/60000]\n",
      "loss: 0.170211  [32032/60000]\n",
      "loss: 0.155546  [35232/60000]\n",
      "loss: 0.150902  [38432/60000]\n",
      "loss: 0.052457  [41632/60000]\n",
      "loss: 0.054892  [44832/60000]\n",
      "loss: 0.248262  [48032/60000]\n",
      "loss: 0.031288  [51232/60000]\n",
      "loss: 0.178163  [54432/60000]\n",
      "loss: 0.198433  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.232334 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.296113  [   32/60000]\n",
      "loss: 0.206530  [ 3232/60000]\n",
      "loss: 0.137590  [ 6432/60000]\n",
      "loss: 0.257323  [ 9632/60000]\n",
      "loss: 0.097060  [12832/60000]\n",
      "loss: 0.195526  [16032/60000]\n",
      "loss: 0.026254  [19232/60000]\n",
      "loss: 0.185815  [22432/60000]\n",
      "loss: 0.126906  [25632/60000]\n",
      "loss: 0.019394  [28832/60000]\n",
      "loss: 0.133680  [32032/60000]\n",
      "loss: 0.328787  [35232/60000]\n",
      "loss: 0.058190  [38432/60000]\n",
      "loss: 0.074196  [41632/60000]\n",
      "loss: 0.012661  [44832/60000]\n",
      "loss: 0.197804  [48032/60000]\n",
      "loss: 0.241866  [51232/60000]\n",
      "loss: 0.229493  [54432/60000]\n",
      "loss: 0.012024  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.192451 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.300549  [   32/60000]\n",
      "loss: 0.264878  [ 3232/60000]\n",
      "loss: 0.267810  [ 6432/60000]\n",
      "loss: 0.044616  [ 9632/60000]\n",
      "loss: 0.059689  [12832/60000]\n",
      "loss: 0.030889  [16032/60000]\n",
      "loss: 0.095963  [19232/60000]\n",
      "loss: 0.074362  [22432/60000]\n",
      "loss: 0.050237  [25632/60000]\n",
      "loss: 0.118855  [28832/60000]\n",
      "loss: 0.463476  [32032/60000]\n",
      "loss: 0.180264  [35232/60000]\n",
      "loss: 0.078760  [38432/60000]\n",
      "loss: 0.021846  [41632/60000]\n",
      "loss: 0.082962  [44832/60000]\n",
      "loss: 0.060800  [48032/60000]\n",
      "loss: 0.130244  [51232/60000]\n",
      "loss: 0.255196  [54432/60000]\n",
      "loss: 0.080680  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.210399 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.457007  [   32/60000]\n",
      "loss: 0.237718  [ 3232/60000]\n",
      "loss: 0.135589  [ 6432/60000]\n",
      "loss: 0.274550  [ 9632/60000]\n",
      "loss: 0.052548  [12832/60000]\n",
      "loss: 0.019460  [16032/60000]\n",
      "loss: 0.271993  [19232/60000]\n",
      "loss: 0.118666  [22432/60000]\n",
      "loss: 0.088269  [25632/60000]\n",
      "loss: 0.173688  [28832/60000]\n",
      "loss: 0.051455  [32032/60000]\n",
      "loss: 0.287689  [35232/60000]\n",
      "loss: 0.129754  [38432/60000]\n",
      "loss: 0.710615  [41632/60000]\n",
      "loss: 0.119914  [44832/60000]\n",
      "loss: 0.081039  [48032/60000]\n",
      "loss: 0.094371  [51232/60000]\n",
      "loss: 0.033174  [54432/60000]\n",
      "loss: 0.191032  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.233116 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.080166  [   32/60000]\n",
      "loss: 0.223970  [ 3232/60000]\n",
      "loss: 0.163699  [ 6432/60000]\n",
      "loss: 0.068322  [ 9632/60000]\n",
      "loss: 0.476017  [12832/60000]\n",
      "loss: 0.150045  [16032/60000]\n",
      "loss: 0.106821  [19232/60000]\n",
      "loss: 0.116913  [22432/60000]\n",
      "loss: 0.547969  [25632/60000]\n",
      "loss: 0.353789  [28832/60000]\n",
      "loss: 0.337664  [32032/60000]\n",
      "loss: 0.092935  [35232/60000]\n",
      "loss: 0.172190  [38432/60000]\n",
      "loss: 0.142444  [41632/60000]\n",
      "loss: 0.334779  [44832/60000]\n",
      "loss: 0.008838  [48032/60000]\n",
      "loss: 0.108457  [51232/60000]\n",
      "loss: 0.029318  [54432/60000]\n",
      "loss: 0.215824  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.201515 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.121442  [   32/60000]\n",
      "loss: 0.296990  [ 3232/60000]\n",
      "loss: 0.066202  [ 6432/60000]\n",
      "loss: 0.423014  [ 9632/60000]\n",
      "loss: 0.070528  [12832/60000]\n",
      "loss: 0.278508  [16032/60000]\n",
      "loss: 0.085647  [19232/60000]\n",
      "loss: 0.155966  [22432/60000]\n",
      "loss: 0.111282  [25632/60000]\n",
      "loss: 0.167910  [28832/60000]\n",
      "loss: 0.089141  [32032/60000]\n",
      "loss: 0.140265  [35232/60000]\n",
      "loss: 0.136240  [38432/60000]\n",
      "loss: 0.027077  [41632/60000]\n",
      "loss: 0.208710  [44832/60000]\n",
      "loss: 0.038373  [48032/60000]\n",
      "loss: 0.144206  [51232/60000]\n",
      "loss: 0.097158  [54432/60000]\n",
      "loss: 0.140419  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.219122 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.112304  [   32/60000]\n",
      "loss: 0.090119  [ 3232/60000]\n",
      "loss: 0.227493  [ 6432/60000]\n",
      "loss: 0.047897  [ 9632/60000]\n",
      "loss: 0.726796  [12832/60000]\n",
      "loss: 0.023685  [16032/60000]\n",
      "loss: 0.123303  [19232/60000]\n",
      "loss: 0.511649  [22432/60000]\n",
      "loss: 0.087754  [25632/60000]\n",
      "loss: 0.480230  [28832/60000]\n",
      "loss: 0.673058  [32032/60000]\n",
      "loss: 0.071059  [35232/60000]\n",
      "loss: 0.175278  [38432/60000]\n",
      "loss: 0.214964  [41632/60000]\n",
      "loss: 0.353909  [44832/60000]\n",
      "loss: 0.047907  [48032/60000]\n",
      "loss: 0.296604  [51232/60000]\n",
      "loss: 0.166349  [54432/60000]\n",
      "loss: 0.031981  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.200173 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.411363  [   32/60000]\n",
      "loss: 0.250750  [ 3232/60000]\n",
      "loss: 0.274529  [ 6432/60000]\n",
      "loss: 0.165833  [ 9632/60000]\n",
      "loss: 0.217363  [12832/60000]\n",
      "loss: 0.287545  [16032/60000]\n",
      "loss: 0.398092  [19232/60000]\n",
      "loss: 0.150239  [22432/60000]\n",
      "loss: 0.120527  [25632/60000]\n",
      "loss: 0.126060  [28832/60000]\n",
      "loss: 0.553780  [32032/60000]\n",
      "loss: 0.243338  [35232/60000]\n",
      "loss: 0.047432  [38432/60000]\n",
      "loss: 0.233465  [41632/60000]\n",
      "loss: 0.092021  [44832/60000]\n",
      "loss: 0.411441  [48032/60000]\n",
      "loss: 0.113402  [51232/60000]\n",
      "loss: 0.056453  [54432/60000]\n",
      "loss: 0.049860  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.199660 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.239054  [   32/60000]\n",
      "loss: 0.015753  [ 3232/60000]\n",
      "loss: 0.068045  [ 6432/60000]\n",
      "loss: 0.097182  [ 9632/60000]\n",
      "loss: 0.243033  [12832/60000]\n",
      "loss: 0.173708  [16032/60000]\n",
      "loss: 0.353316  [19232/60000]\n",
      "loss: 0.242920  [22432/60000]\n",
      "loss: 0.097239  [25632/60000]\n",
      "loss: 0.028569  [28832/60000]\n",
      "loss: 0.085694  [32032/60000]\n",
      "loss: 0.039789  [35232/60000]\n",
      "loss: 0.258389  [38432/60000]\n",
      "loss: 0.266341  [41632/60000]\n",
      "loss: 0.173697  [44832/60000]\n",
      "loss: 0.187682  [48032/60000]\n",
      "loss: 0.032835  [51232/60000]\n",
      "loss: 0.066804  [54432/60000]\n",
      "loss: 0.170586  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.194165 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.081081  [   32/60000]\n",
      "loss: 0.147447  [ 3232/60000]\n",
      "loss: 0.032021  [ 6432/60000]\n",
      "loss: 0.419161  [ 9632/60000]\n",
      "loss: 0.386479  [12832/60000]\n",
      "loss: 0.217691  [16032/60000]\n",
      "loss: 0.236208  [19232/60000]\n",
      "loss: 0.021130  [22432/60000]\n",
      "loss: 0.034734  [25632/60000]\n",
      "loss: 0.275180  [28832/60000]\n",
      "loss: 0.160702  [32032/60000]\n",
      "loss: 0.310591  [35232/60000]\n",
      "loss: 0.102552  [38432/60000]\n",
      "loss: 0.112908  [41632/60000]\n",
      "loss: 0.105852  [44832/60000]\n",
      "loss: 0.130599  [48032/60000]\n",
      "loss: 0.086525  [51232/60000]\n",
      "loss: 0.175378  [54432/60000]\n",
      "loss: 0.199292  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.204633 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.254707  [   32/60000]\n",
      "loss: 0.177162  [ 3232/60000]\n",
      "loss: 0.014235  [ 6432/60000]\n",
      "loss: 0.054235  [ 9632/60000]\n",
      "loss: 0.040333  [12832/60000]\n",
      "loss: 0.143637  [16032/60000]\n",
      "loss: 0.182320  [19232/60000]\n",
      "loss: 0.348203  [22432/60000]\n",
      "loss: 0.117218  [25632/60000]\n",
      "loss: 0.197399  [28832/60000]\n",
      "loss: 0.380066  [32032/60000]\n",
      "loss: 0.261149  [35232/60000]\n",
      "loss: 0.111043  [38432/60000]\n",
      "loss: 0.161651  [41632/60000]\n",
      "loss: 0.075280  [44832/60000]\n",
      "loss: 0.091413  [48032/60000]\n",
      "loss: 0.338795  [51232/60000]\n",
      "loss: 0.074486  [54432/60000]\n",
      "loss: 0.124797  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.209216 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.068140  [   32/60000]\n",
      "loss: 0.155972  [ 3232/60000]\n",
      "loss: 0.050125  [ 6432/60000]\n",
      "loss: 0.106812  [ 9632/60000]\n",
      "loss: 0.101610  [12832/60000]\n",
      "loss: 0.203044  [16032/60000]\n",
      "loss: 0.144257  [19232/60000]\n",
      "loss: 0.024452  [22432/60000]\n",
      "loss: 0.108051  [25632/60000]\n",
      "loss: 0.107506  [28832/60000]\n",
      "loss: 0.079587  [32032/60000]\n",
      "loss: 0.085986  [35232/60000]\n",
      "loss: 0.298496  [38432/60000]\n",
      "loss: 0.163378  [41632/60000]\n",
      "loss: 0.101363  [44832/60000]\n",
      "loss: 0.027634  [48032/60000]\n",
      "loss: 0.039529  [51232/60000]\n",
      "loss: 0.165246  [54432/60000]\n",
      "loss: 0.073401  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.197648 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.132150  [   32/60000]\n",
      "loss: 0.030280  [ 3232/60000]\n",
      "loss: 0.048246  [ 6432/60000]\n",
      "loss: 0.176362  [ 9632/60000]\n",
      "loss: 0.376138  [12832/60000]\n",
      "loss: 0.064547  [16032/60000]\n",
      "loss: 0.168466  [19232/60000]\n",
      "loss: 0.039678  [22432/60000]\n",
      "loss: 0.052740  [25632/60000]\n",
      "loss: 0.091105  [28832/60000]\n",
      "loss: 0.088696  [32032/60000]\n",
      "loss: 0.017575  [35232/60000]\n",
      "loss: 0.690260  [38432/60000]\n",
      "loss: 0.025719  [41632/60000]\n",
      "loss: 0.239779  [44832/60000]\n",
      "loss: 0.079811  [48032/60000]\n",
      "loss: 0.110576  [51232/60000]\n",
      "loss: 0.078151  [54432/60000]\n",
      "loss: 0.124809  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.208175 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.024134  [   32/60000]\n",
      "loss: 0.182320  [ 3232/60000]\n",
      "loss: 0.269957  [ 6432/60000]\n",
      "loss: 0.186344  [ 9632/60000]\n",
      "loss: 0.337930  [12832/60000]\n",
      "loss: 0.067586  [16032/60000]\n",
      "loss: 0.197879  [19232/60000]\n",
      "loss: 0.055906  [22432/60000]\n",
      "loss: 0.023462  [25632/60000]\n",
      "loss: 0.057800  [28832/60000]\n",
      "loss: 0.236307  [32032/60000]\n",
      "loss: 0.199658  [35232/60000]\n",
      "loss: 0.028086  [38432/60000]\n",
      "loss: 0.042594  [41632/60000]\n",
      "loss: 0.175345  [44832/60000]\n",
      "loss: 0.211273  [48032/60000]\n",
      "loss: 0.043911  [51232/60000]\n",
      "loss: 0.019617  [54432/60000]\n",
      "loss: 0.137003  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.250226 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.052344  [   32/60000]\n",
      "loss: 0.201104  [ 3232/60000]\n",
      "loss: 0.032957  [ 6432/60000]\n",
      "loss: 0.159819  [ 9632/60000]\n",
      "loss: 0.205864  [12832/60000]\n",
      "loss: 0.071649  [16032/60000]\n",
      "loss: 0.037677  [19232/60000]\n",
      "loss: 0.195606  [22432/60000]\n",
      "loss: 0.063438  [25632/60000]\n",
      "loss: 0.194926  [28832/60000]\n",
      "loss: 0.144634  [32032/60000]\n",
      "loss: 0.046692  [35232/60000]\n",
      "loss: 0.226253  [38432/60000]\n",
      "loss: 0.079809  [41632/60000]\n",
      "loss: 0.129427  [44832/60000]\n",
      "loss: 0.168766  [48032/60000]\n",
      "loss: 0.066216  [51232/60000]\n",
      "loss: 0.178765  [54432/60000]\n",
      "loss: 0.244117  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.205389 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.128074  [   32/60000]\n",
      "loss: 0.071970  [ 3232/60000]\n",
      "loss: 0.569104  [ 6432/60000]\n",
      "loss: 0.323963  [ 9632/60000]\n",
      "loss: 0.050373  [12832/60000]\n",
      "loss: 0.110254  [16032/60000]\n",
      "loss: 0.094472  [19232/60000]\n",
      "loss: 0.127564  [22432/60000]\n",
      "loss: 0.235390  [25632/60000]\n",
      "loss: 0.116837  [28832/60000]\n",
      "loss: 0.154032  [32032/60000]\n",
      "loss: 0.040253  [35232/60000]\n",
      "loss: 0.167027  [38432/60000]\n",
      "loss: 0.101279  [41632/60000]\n",
      "loss: 0.066029  [44832/60000]\n",
      "loss: 0.025763  [48032/60000]\n",
      "loss: 0.028945  [51232/60000]\n",
      "loss: 0.102547  [54432/60000]\n",
      "loss: 0.216609  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.214427 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.107485  [   32/60000]\n",
      "loss: 0.111133  [ 3232/60000]\n",
      "loss: 0.057021  [ 6432/60000]\n",
      "loss: 0.100985  [ 9632/60000]\n",
      "loss: 0.101228  [12832/60000]\n",
      "loss: 0.050985  [16032/60000]\n",
      "loss: 0.116671  [19232/60000]\n",
      "loss: 0.049702  [22432/60000]\n",
      "loss: 0.033326  [25632/60000]\n",
      "loss: 0.026613  [28832/60000]\n",
      "loss: 0.312698  [32032/60000]\n",
      "loss: 0.053262  [35232/60000]\n",
      "loss: 0.075265  [38432/60000]\n",
      "loss: 0.044765  [41632/60000]\n",
      "loss: 0.137487  [44832/60000]\n",
      "loss: 0.335326  [48032/60000]\n",
      "loss: 0.333826  [51232/60000]\n",
      "loss: 0.151834  [54432/60000]\n",
      "loss: 0.009378  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.203277 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.548014  [   32/60000]\n",
      "loss: 0.043313  [ 3232/60000]\n",
      "loss: 0.360367  [ 6432/60000]\n",
      "loss: 0.052043  [ 9632/60000]\n",
      "loss: 0.160450  [12832/60000]\n",
      "loss: 0.050450  [16032/60000]\n",
      "loss: 0.070019  [19232/60000]\n",
      "loss: 0.365042  [22432/60000]\n",
      "loss: 0.059095  [25632/60000]\n",
      "loss: 0.170987  [28832/60000]\n",
      "loss: 0.117513  [32032/60000]\n",
      "loss: 0.168290  [35232/60000]\n",
      "loss: 0.124896  [38432/60000]\n",
      "loss: 0.299003  [41632/60000]\n",
      "loss: 0.336960  [44832/60000]\n",
      "loss: 0.040121  [48032/60000]\n",
      "loss: 0.113070  [51232/60000]\n",
      "loss: 0.084581  [54432/60000]\n",
      "loss: 0.197485  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.220711 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.140021  [   32/60000]\n",
      "loss: 0.338760  [ 3232/60000]\n",
      "loss: 0.140740  [ 6432/60000]\n",
      "loss: 0.353089  [ 9632/60000]\n",
      "loss: 0.067728  [12832/60000]\n",
      "loss: 0.152023  [16032/60000]\n",
      "loss: 0.191398  [19232/60000]\n",
      "loss: 0.198756  [22432/60000]\n",
      "loss: 0.095241  [25632/60000]\n",
      "loss: 0.245855  [28832/60000]\n",
      "loss: 0.071532  [32032/60000]\n",
      "loss: 0.413144  [35232/60000]\n",
      "loss: 0.030083  [38432/60000]\n",
      "loss: 0.017666  [41632/60000]\n",
      "loss: 0.253767  [44832/60000]\n",
      "loss: 0.303526  [48032/60000]\n",
      "loss: 0.216581  [51232/60000]\n",
      "loss: 0.377772  [54432/60000]\n",
      "loss: 0.018094  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.203088 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.081066  [   32/60000]\n",
      "loss: 0.084966  [ 3232/60000]\n",
      "loss: 0.167709  [ 6432/60000]\n",
      "loss: 0.030289  [ 9632/60000]\n",
      "loss: 0.132585  [12832/60000]\n",
      "loss: 0.299772  [16032/60000]\n",
      "loss: 0.079313  [19232/60000]\n",
      "loss: 0.304183  [22432/60000]\n",
      "loss: 0.318664  [25632/60000]\n",
      "loss: 0.137664  [28832/60000]\n",
      "loss: 0.160028  [32032/60000]\n",
      "loss: 0.088929  [35232/60000]\n",
      "loss: 0.162762  [38432/60000]\n",
      "loss: 0.078345  [41632/60000]\n",
      "loss: 0.084275  [44832/60000]\n",
      "loss: 0.056904  [48032/60000]\n",
      "loss: 0.073867  [51232/60000]\n",
      "loss: 0.462365  [54432/60000]\n",
      "loss: 0.353306  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.217274 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.442718  [   32/60000]\n",
      "loss: 0.174133  [ 3232/60000]\n",
      "loss: 0.078702  [ 6432/60000]\n",
      "loss: 0.018314  [ 9632/60000]\n",
      "loss: 0.244682  [12832/60000]\n",
      "loss: 0.208671  [16032/60000]\n",
      "loss: 0.199657  [19232/60000]\n",
      "loss: 0.177599  [22432/60000]\n",
      "loss: 0.044939  [25632/60000]\n",
      "loss: 0.132880  [28832/60000]\n",
      "loss: 0.187256  [32032/60000]\n",
      "loss: 0.182222  [35232/60000]\n",
      "loss: 0.282344  [38432/60000]\n",
      "loss: 0.132641  [41632/60000]\n",
      "loss: 0.268560  [44832/60000]\n",
      "loss: 0.077848  [48032/60000]\n",
      "loss: 0.310719  [51232/60000]\n",
      "loss: 0.383528  [54432/60000]\n",
      "loss: 0.042909  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.203799 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.093954  [   32/60000]\n",
      "loss: 0.384901  [ 3232/60000]\n",
      "loss: 0.125393  [ 6432/60000]\n",
      "loss: 0.043096  [ 9632/60000]\n",
      "loss: 0.186322  [12832/60000]\n",
      "loss: 0.092433  [16032/60000]\n",
      "loss: 0.031178  [19232/60000]\n",
      "loss: 0.244269  [22432/60000]\n",
      "loss: 0.047397  [25632/60000]\n",
      "loss: 0.139616  [28832/60000]\n",
      "loss: 0.091999  [32032/60000]\n",
      "loss: 0.140760  [35232/60000]\n",
      "loss: 0.217990  [38432/60000]\n",
      "loss: 0.269763  [41632/60000]\n",
      "loss: 0.076157  [44832/60000]\n",
      "loss: 0.037022  [48032/60000]\n",
      "loss: 0.097681  [51232/60000]\n",
      "loss: 0.139398  [54432/60000]\n",
      "loss: 0.446552  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.199416 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.472648  [   32/60000]\n",
      "loss: 0.055400  [ 3232/60000]\n",
      "loss: 0.102593  [ 6432/60000]\n",
      "loss: 0.133426  [ 9632/60000]\n",
      "loss: 0.149081  [12832/60000]\n",
      "loss: 0.121019  [16032/60000]\n",
      "loss: 0.275731  [19232/60000]\n",
      "loss: 0.142514  [22432/60000]\n",
      "loss: 0.280589  [25632/60000]\n",
      "loss: 0.439365  [28832/60000]\n",
      "loss: 0.253583  [32032/60000]\n",
      "loss: 0.148376  [35232/60000]\n",
      "loss: 0.090473  [38432/60000]\n",
      "loss: 0.127075  [41632/60000]\n",
      "loss: 0.007596  [44832/60000]\n",
      "loss: 0.119830  [48032/60000]\n",
      "loss: 0.159208  [51232/60000]\n",
      "loss: 0.252249  [54432/60000]\n",
      "loss: 0.164734  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.211893 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.114159  [   32/60000]\n",
      "loss: 0.129724  [ 3232/60000]\n",
      "loss: 0.071591  [ 6432/60000]\n",
      "loss: 0.043618  [ 9632/60000]\n",
      "loss: 0.036755  [12832/60000]\n",
      "loss: 0.260009  [16032/60000]\n",
      "loss: 0.824417  [19232/60000]\n",
      "loss: 0.328142  [22432/60000]\n",
      "loss: 0.047100  [25632/60000]\n",
      "loss: 0.066175  [28832/60000]\n",
      "loss: 0.168759  [32032/60000]\n",
      "loss: 0.068343  [35232/60000]\n",
      "loss: 0.036445  [38432/60000]\n",
      "loss: 0.191166  [41632/60000]\n",
      "loss: 0.113056  [44832/60000]\n",
      "loss: 0.032161  [48032/60000]\n",
      "loss: 0.045433  [51232/60000]\n",
      "loss: 0.110537  [54432/60000]\n",
      "loss: 0.180618  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.204963 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(mnist_train, model, loss, optimizer)\n",
    "    test_loop(mnist_test, model, loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'models/10w1a32a40.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OptProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
